{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016707,
     "end_time": "2021-05-06T18:29:57.194049",
     "exception": false,
     "start_time": "2021-05-06T18:29:57.177342",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Thanks to https://www.kaggle.com/dschettler8845/hpa-cellwise-classification-inference and https://www.kaggle.com/h053473666 for adding a multi-label classification model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.015019,
     "end_time": "2021-05-06T18:29:57.224399",
     "exception": false,
     "start_time": "2021-05-06T18:29:57.209380",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-06T18:29:57.258340Z",
     "iopub.status.busy": "2021-05-06T18:29:57.257676Z",
     "iopub.status.idle": "2021-05-06T18:30:28.155301Z",
     "shell.execute_reply": "2021-05-06T18:30:28.154395Z"
    },
    "papermill": {
     "duration": 30.915917,
     "end_time": "2021-05-06T18:30:28.155525",
     "exception": false,
     "start_time": "2021-05-06T18:29:57.239608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./focal-loss-master\r\n",
      "Requirement already satisfied: tensorflow>=2.2 in /opt/conda/lib/python3.7/site-packages (from focal-loss==0.0.7) (2.4.0)\r\n",
      "Requirement already satisfied: h5py~=2.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.2->focal-loss==0.0.7) (2.10.0)\r\n",
      "Requirement already satisfied: grpcio~=1.32.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.2->focal-loss==0.0.7) (1.32.0)\r\n",
      "Requirement already satisfied: absl-py~=0.10 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.2->focal-loss==0.0.7) (0.10.0)\r\n",
      "Requirement already satisfied: six~=1.15.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.2->focal-loss==0.0.7) (1.15.0)\r\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.2->focal-loss==0.0.7) (1.12)\r\n",
      "Requirement already satisfied: wheel~=0.35 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.2->focal-loss==0.0.7) (0.36.2)\r\n",
      "Requirement already satisfied: gast==0.3.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.2->focal-loss==0.0.7) (0.3.3)\r\n",
      "Requirement already satisfied: numpy~=1.19.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.2->focal-loss==0.0.7) (1.19.5)\r\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.2->focal-loss==0.0.7) (3.3.0)\r\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.2->focal-loss==0.0.7) (1.6.3)\r\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.2->focal-loss==0.0.7) (1.1.2)\r\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.2->focal-loss==0.0.7) (3.14.0)\r\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.2->focal-loss==0.0.7) (1.1.0)\r\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.2->focal-loss==0.0.7) (1.12.1)\r\n",
      "Requirement already satisfied: tensorboard~=2.4 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.2->focal-loss==0.0.7) (2.4.1)\r\n",
      "Requirement already satisfied: google-pasta~=0.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.2->focal-loss==0.0.7) (0.2.0)\r\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.2->focal-loss==0.0.7) (3.7.4.3)\r\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.2->focal-loss==0.0.7) (2.4.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow>=2.2->focal-loss==0.0.7) (3.3.3)\r\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow>=2.2->focal-loss==0.0.7) (1.8.0)\r\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow>=2.2->focal-loss==0.0.7) (49.6.0.post20201009)\r\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow>=2.2->focal-loss==0.0.7) (1.0.1)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow>=2.2->focal-loss==0.0.7) (2.25.1)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow>=2.2->focal-loss==0.0.7) (0.4.2)\r\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.4->tensorflow>=2.2->focal-loss==0.0.7) (1.24.0)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2->focal-loss==0.0.7) (0.2.7)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2->focal-loss==0.0.7) (4.6)\r\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2->focal-loss==0.0.7) (4.1.1)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.2->focal-loss==0.0.7) (1.3.0)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.2->focal-loss==0.0.7) (3.3.0)\r\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2->focal-loss==0.0.7) (0.4.8)\r\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2->focal-loss==0.0.7) (3.0.4)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2->focal-loss==0.0.7) (2.10)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2->focal-loss==0.0.7) (2020.12.5)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2->focal-loss==0.0.7) (1.26.2)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.2->focal-loss==0.0.7) (3.0.1)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.2->focal-loss==0.0.7) (3.4.0)\r\n",
      "Building wheels for collected packages: focal-loss\r\n",
      "  Building wheel for focal-loss (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for focal-loss: filename=focal_loss-0.0.7-py3-none-any.whl size=19047 sha256=6ccb02fcef06975f24583fee0940b75c0d73ceeb3457c2a080af1bcfcfdd195f\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/e8/d5/51/8a79145e0db880f98e770db208d5cbf7352dfff967a45b0946\r\n",
      "Successfully built focal-loss\r\n",
      "Installing collected packages: focal-loss\r\n",
      "Successfully installed focal-loss-0.0.7\r\n"
     ]
    }
   ],
   "source": [
    "!cp -r ../input/focallosstensorflowstablefromartemmavrin/focal-loss-master/* ./\n",
    "!pip install ./focal-loss-master/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-06T18:30:28.205109Z",
     "iopub.status.busy": "2021-05-06T18:30:28.204434Z",
     "iopub.status.idle": "2021-05-06T18:30:34.610660Z",
     "shell.execute_reply": "2021-05-06T18:30:34.609780Z"
    },
    "papermill": {
     "duration": 6.435222,
     "end_time": "2021-05-06T18:30:34.610825",
     "exception": false,
     "start_time": "2021-05-06T18:30:28.175603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from focal_loss import BinaryFocalLoss  # Used by the model here: https://www.kaggle.com/aristotelisch/hpa-classification-efnb7-train-13cc0d.\n",
    "\n",
    "def binary_focal_loss(gamma=2, alpha=0.25):\n",
    "    \"\"\"\n",
    "    Binary form of focal loss.\n",
    "         Focal loss for binary classification problems\n",
    "    \n",
    "    focal_loss(p_t) = -alpha_t * (1 - p_t)**gamma * log(p_t)\n",
    "        where p = sigmoid(x), p_t = p or 1 - p depending on if the label is 1 or 0, respectively.\n",
    "    References:\n",
    "        https://arxiv.org/pdf/1708.02002.pdf\n",
    "    Usage:\n",
    "     model.compile(loss=[binary_focal_loss(alpha=.25, gamma=2)], metrics=[\"accuracy\"], optimizer=adam)\n",
    "    \"\"\"\n",
    "    alpha = tf.constant(alpha, dtype=tf.float32)\n",
    "    gamma = tf.constant(gamma, dtype=tf.float32)\n",
    "\n",
    "    def binary_focal_loss_fixed(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        y_true shape need be (None,1)\n",
    "        y_pred need be compute after sigmoid\n",
    "        \"\"\"\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        alpha_t = y_true*alpha + (K.ones_like(y_true)-y_true)*(1-alpha)\n",
    "    \n",
    "        p_t = y_true*y_pred + (K.ones_like(y_true)-y_true)*(K.ones_like(y_true)-y_pred) + K.epsilon()\n",
    "        focal_loss = - alpha_t * K.pow((K.ones_like(y_true)-p_t),gamma) * K.log(p_t)\n",
    "        return K.mean(focal_loss)\n",
    "    return binary_focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-06T18:30:34.660835Z",
     "iopub.status.busy": "2021-05-06T18:30:34.654027Z",
     "iopub.status.idle": "2021-05-06T18:31:03.063116Z",
     "shell.execute_reply": "2021-05-06T18:31:03.062419Z"
    },
    "papermill": {
     "duration": 28.432928,
     "end_time": "2021-05-06T18:31:03.063275",
     "exception": false,
     "start_time": "2021-05-06T18:30:34.630347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install /kaggle/input/kerasapplications -q\n",
    "#!pip install keras-resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-05-06T18:31:03.129781Z",
     "iopub.status.busy": "2021-05-06T18:31:03.114052Z",
     "iopub.status.idle": "2021-05-06T18:32:30.429047Z",
     "shell.execute_reply": "2021-05-06T18:32:30.429793Z"
    },
    "papermill": {
     "duration": 87.346045,
     "end_time": "2021-05-06T18:32:30.430053",
     "exception": false,
     "start_time": "2021-05-06T18:31:03.084008",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "... INSTALLING AND IMPORTING CELL-PROFILER TOOL (HPACELLSEG) ...\n",
      "\n",
      "\n",
      "... OTHER IMPORTS STARTING ...\n",
      "\n",
      "\n",
      "\tVERSION INFORMATION\n",
      "\t\t– TENSORFLOW VERSION: 2.4.0\n",
      "\t\t– NUMPY VERSION: 1.19.5\n",
      "\t\t– MATPLOTLIB VERSION: 3.3.3\n",
      "\n",
      "\n",
      "... IMPORTS COMPLETE ...\n",
      "\n",
      "\n",
      "... ONLY INFERRING ON PUBLIC TEST DATA (USING PRE-PROCESSED DF) ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell Segmentator Tool\n",
    "print(\"\\n... INSTALLING AND IMPORTING CELL-PROFILER TOOL (HPACELLSEG) ...\\n\")\n",
    "try:\n",
    "    import hpacellseg.cellsegmentator as cellsegmentator\n",
    "    from hpacellseg.utils import label_cell\n",
    "except:\n",
    "    !pip install -q \"/kaggle/input/pycocotools/pycocotools-2.0-cp37-cp37m-linux_x86_64.whl\"\n",
    "    !pip install -q \"/kaggle/input/hpapytorchzoozip/pytorch_zoo-master\"\n",
    "    !pip install -q \"/kaggle/input/hpacellsegmentatormaster/HPA-Cell-Segmentation-master\"\n",
    "    import hpacellseg.cellsegmentator as cellsegmentator\n",
    "    from hpacellseg.utils import label_cell\n",
    "\n",
    "print(\"\\n... OTHER IMPORTS STARTING ...\\n\")\n",
    "print(\"\\n\\tVERSION INFORMATION\")\n",
    "\n",
    "# Machine Learning and Data Science Imports\n",
    "import tensorflow as tf; print(f\"\\t\\t– TENSORFLOW VERSION: {tf.__version__}\");\n",
    "import pandas as pd; pd.options.mode.chained_assignment = None;\n",
    "import numpy as np; print(f\"\\t\\t– NUMPY VERSION: {np.__version__}\");\n",
    "import torch\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# Built In Imports\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import multiprocessing\n",
    "from glob import glob\n",
    "import warnings\n",
    "import requests\n",
    "import imageio\n",
    "import IPython\n",
    "import urllib\n",
    "import zipfile\n",
    "import pickle\n",
    "import random\n",
    "import shutil\n",
    "import string\n",
    "import math\n",
    "import tqdm\n",
    "import time\n",
    "import gzip\n",
    "import sys\n",
    "import ast\n",
    "import csv; csv.field_size_limit(sys.maxsize)\n",
    "import io\n",
    "import os\n",
    "import gc\n",
    "import re\n",
    "\n",
    "# Visualization Imports\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.patches as patches\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import matplotlib; print(f\"\\t\\t– MATPLOTLIB VERSION: {matplotlib.__version__}\");\n",
    "import plotly\n",
    "import PIL\n",
    "import cv2\n",
    "\n",
    "# Submission Imports\n",
    "from pycocotools import _mask as coco_mask\n",
    "import typing as t\n",
    "import base64\n",
    "import zlib\n",
    "\n",
    "# PRESETS\n",
    "LBL_NAMES = [\"Nucleoplasm\", \"Nuclear Membrane\", \"Nucleoli\", \"Nucleoli Fibrillar Center\", \"Nuclear Speckles\", \"Nuclear Bodies\", \"Endoplasmic Reticulum\", \"Golgi Apparatus\", \"Intermediate Filaments\", \"Actin Filaments\", \"Microtubules\", \"Mitotic Spindle\", \"Centrosome\", \"Plasma Membrane\", \"Mitochondria\", \"Aggresome\", \"Cytosol\", \"Vesicles\", \"Negative\"]\n",
    "INT_2_STR = {x:LBL_NAMES[x] for x in np.arange(19)}\n",
    "INT_2_STR_LOWER = {k:v.lower().replace(\" \", \"_\") for k,v in INT_2_STR.items()}\n",
    "STR_2_INT_LOWER = {v:k for k,v in INT_2_STR_LOWER.items()}\n",
    "STR_2_INT = {v:k for k,v in INT_2_STR.items()}\n",
    "FIG_FONT = dict(family=\"Helvetica, Arial\", size=14, color=\"#7f7f7f\")\n",
    "LABEL_COLORS = [px.colors.label_rgb(px.colors.convert_to_RGB_255(x)) for x in sns.color_palette(\"Spectral\", len(LBL_NAMES))]\n",
    "LABEL_COL_MAP = {str(i):x for i,x in enumerate(LABEL_COLORS)}\n",
    "\n",
    "print(\"\\n\\n... IMPORTS COMPLETE ...\\n\")\n",
    "\n",
    "##### THIS IS FOR PROTOTYPING AND PUBLIC LB PROBING #####\n",
    "ONLY_PUBLIC = True\n",
    "##### THIS IS FOR PROTOTYPING AND PUBLIC LB PROBING#####\n",
    "\n",
    "if ONLY_PUBLIC:\n",
    "    print(\"\\n... ONLY INFERRING ON PUBLIC TEST DATA (USING PRE-PROCESSED DF) ...\\n\")\n",
    "else:\n",
    "    # Stop Tensorflow From Eating All The Memory\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-06T18:32:30.475503Z",
     "iopub.status.busy": "2021-05-06T18:32:30.474816Z",
     "iopub.status.idle": "2021-05-06T18:32:32.994961Z",
     "shell.execute_reply": "2021-05-06T18:32:32.995503Z"
    },
    "papermill": {
     "duration": 2.544264,
     "end_time": "2021-05-06T18:32:32.995726",
     "exception": false,
     "start_time": "2021-05-06T18:32:30.451462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... The number of testing images is 2236\n",
      "\t--> i.e. 559 4-channel images ...\n",
      "\n",
      "\n",
      "SAMPLE SUBMISSION DATAFRAME1\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>ImageWidth</th>\n",
       "      <th>ImageHeight</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0040581b-f1f2-4fbe-b043-b6bfea5404bb</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>0 1 eNoLCAgIMAEABJkBdQ==</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>004a270d-34a2-4d60-bbe4-365fca868193</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>0 1 eNoLCAgIMAEABJkBdQ==</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00537262-883c-4b37-a3a1-a4931b6faea5</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>0 1 eNoLCAgIMAEABJkBdQ==</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00c9a1c9-2f06-476f-8b0d-6d01032874a2</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>0 1 eNoLCAgIMAEABJkBdQ==</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0173029a-161d-40ef-af28-2342915b22fb</td>\n",
       "      <td>3072</td>\n",
       "      <td>3072</td>\n",
       "      <td>0 1 eNoLCAgIsAQABJ4Beg==</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>fea47298-266a-4cf4-93bd-55d1bcc2fc7d</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>0 1 eNoLCAjJNgIABNkBkg==</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>feb955db-6c07-4717-a98b-92236c8e01d8</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>0 1 eNoLCAgIMAEABJkBdQ==</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>fefb9bb7-934a-40d1-8d2f-210265857388</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>0 1 eNoLCAgIMAEABJkBdQ==</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>ff069fa2-d948-408e-91b3-034cfea428d1</td>\n",
       "      <td>3072</td>\n",
       "      <td>3072</td>\n",
       "      <td>0 1 eNoLCAgIsAQABJ4Beg==</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>ff23eea9-4bbe-42af-a8da-9ae16321fc6d</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>0 1 eNoLCAgIMAEABJkBdQ==</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>559 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       ID  ImageWidth  ImageHeight  \\\n",
       "0    0040581b-f1f2-4fbe-b043-b6bfea5404bb        2048         2048   \n",
       "1    004a270d-34a2-4d60-bbe4-365fca868193        2048         2048   \n",
       "2    00537262-883c-4b37-a3a1-a4931b6faea5        2048         2048   \n",
       "3    00c9a1c9-2f06-476f-8b0d-6d01032874a2        2048         2048   \n",
       "4    0173029a-161d-40ef-af28-2342915b22fb        3072         3072   \n",
       "..                                    ...         ...          ...   \n",
       "554  fea47298-266a-4cf4-93bd-55d1bcc2fc7d        1728         1728   \n",
       "555  feb955db-6c07-4717-a98b-92236c8e01d8        2048         2048   \n",
       "556  fefb9bb7-934a-40d1-8d2f-210265857388        2048         2048   \n",
       "557  ff069fa2-d948-408e-91b3-034cfea428d1        3072         3072   \n",
       "558  ff23eea9-4bbe-42af-a8da-9ae16321fc6d        2048         2048   \n",
       "\n",
       "             PredictionString  \n",
       "0    0 1 eNoLCAgIMAEABJkBdQ==  \n",
       "1    0 1 eNoLCAgIMAEABJkBdQ==  \n",
       "2    0 1 eNoLCAgIMAEABJkBdQ==  \n",
       "3    0 1 eNoLCAgIMAEABJkBdQ==  \n",
       "4    0 1 eNoLCAgIsAQABJ4Beg==  \n",
       "..                        ...  \n",
       "554  0 1 eNoLCAjJNgIABNkBkg==  \n",
       "555  0 1 eNoLCAgIMAEABJkBdQ==  \n",
       "556  0 1 eNoLCAgIMAEABJkBdQ==  \n",
       "557  0 1 eNoLCAgIsAQABJ4Beg==  \n",
       "558  0 1 eNoLCAgIMAEABJkBdQ==  \n",
       "\n",
       "[559 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "TEST DATAFRAME W/ MASKS\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>ImageWidth</th>\n",
       "      <th>ImageHeight</th>\n",
       "      <th>PredictionString</th>\n",
       "      <th>mask_rles</th>\n",
       "      <th>mask_bboxes</th>\n",
       "      <th>mask_sub_rles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0040581b-f1f2-4fbe-b043-b6bfea5404bb</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>0 1 eNoLCAgIMAEABJkBdQ==</td>\n",
       "      <td>[729089 8 729109 12 731137 8 731157 12 733185 ...</td>\n",
       "      <td>[(356, 0, 1076, 244), (764, 0, 1456, 756), (15...</td>\n",
       "      <td>[eNqtVL0OgyAQfiVIz4TBoYODiVdKE2odGDqYRi1p338rr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>004a270d-34a2-4d60-bbe4-365fca868193</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>0 1 eNoLCAgIMAEABJkBdQ==</td>\n",
       "      <td>[557057 4 559105 4 561153 4 563201 4 565249 48...</td>\n",
       "      <td>[(272, 0, 564, 196), (1648, 0, 2048, 260), (11...</td>\n",
       "      <td>[eNoLCAhINDDJyTc0AIMYwxQ/CCvBwAHCsPCA0DYuqDRcg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00537262-883c-4b37-a3a1-a4931b6faea5</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>0 1 eNoLCAgIMAEABJkBdQ==</td>\n",
       "      <td>[1 92 2049 92 4097 92 6145 92 8193 96 10241 96...</td>\n",
       "      <td>[(0, 0, 304, 380), (712, 0, 1596, 384), (1772,...</td>\n",
       "      <td>[eNozyDEKyTU0AAMTHwOsACaOi7ZxQaUTDBwgjBjDFD80I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00c9a1c9-2f06-476f-8b0d-6d01032874a2</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>0 1 eNoLCAgIMAEABJkBdQ==</td>\n",
       "      <td>[1171605 16 1173653 16 1175701 16 1177749 16 1...</td>\n",
       "      <td>[(572, 0, 1092, 264), (1512, 156, 2048, 684), ...</td>\n",
       "      <td>[eNrFk7ESwiAMhl8puWNgYOjAwIAsou3AwNC7gvbO99/Ua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0173029a-161d-40ef-af28-2342915b22fb</td>\n",
       "      <td>3072</td>\n",
       "      <td>3072</td>\n",
       "      <td>0 1 eNoLCAgIsAQABJ4Beg==</td>\n",
       "      <td>[1 558 3073 558 6145 558 9217 558 12289 558 15...</td>\n",
       "      <td>[(0, 0, 672, 624), (258, 0, 882, 318), (882, 0...</td>\n",
       "      <td>[eNq9VMEKwjAM/aVQsE7ZRSgbCKVzh1mnVK1zjjH0/296c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>fea47298-266a-4cf4-93bd-55d1bcc2fc7d</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>0 1 eNoLCAjJNgIABNkBkg==</td>\n",
       "      <td>[2555936 17 2557664 17 2559392 17 2561090 64 2...</td>\n",
       "      <td>[(1479, 0, 1728, 341), (736, 31, 1367, 827), (...</td>\n",
       "      <td>[eNqFUMEOgjAM/aU3tzijN02IIxtDEhJPgEajJ/3/m6xlM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>feb955db-6c07-4717-a98b-92236c8e01d8</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>0 1 eNoLCAgIMAEABJkBdQ==</td>\n",
       "      <td>[1 456 597 184 2049 456 2645 184 4097 456 4693...</td>\n",
       "      <td>[(0, 0, 216, 784), (208, 0, 796, 512), (640, 0...</td>\n",
       "      <td>[eNrFlU2L2zAQQP+SJdvBh2XpLVmwFEEnmwkIOpQhGTeC/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>fefb9bb7-934a-40d1-8d2f-210265857388</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>0 1 eNoLCAgIMAEABJkBdQ==</td>\n",
       "      <td>[1 332 2049 332 4097 332 6145 332 8193 332 102...</td>\n",
       "      <td>[(0, 0, 496, 336), (672, 0, 1732, 680), (1516,...</td>\n",
       "      <td>[eNoziLFKSTU0QAEmPgZkAR8T8uRh4oRoDwvSxAnZB9PnY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>ff069fa2-d948-408e-91b3-034cfea428d1</td>\n",
       "      <td>3072</td>\n",
       "      <td>3072</td>\n",
       "      <td>0 1 eNoLCAgIsAQABJ4Beg==</td>\n",
       "      <td>[2377891 60 2380963 60 2384035 60 2387107 60 2...</td>\n",
       "      <td>[(774, 0, 1674, 402), (1338, 0, 2244, 810), (1...</td>\n",
       "      <td>[eNoLCk2KMMoxDMkzMoCBNL8gowh/ONcrycAFzonzz0Piu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>ff23eea9-4bbe-42af-a8da-9ae16321fc6d</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>0 1 eNoLCAgIMAEABJkBdQ==</td>\n",
       "      <td>[1 268 349 80 2049 268 2397 80 4097 268 4445 8...</td>\n",
       "      <td>[(0, 0, 244, 528), (180, 0, 504, 636), (728, 0...</td>\n",
       "      <td>[eNq9ksFqwzAMhl8pauPNHTkMVmjxGkUwH3QwtQI+6OD3P...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>559 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       ID  ImageWidth  ImageHeight  \\\n",
       "0    0040581b-f1f2-4fbe-b043-b6bfea5404bb        2048         2048   \n",
       "1    004a270d-34a2-4d60-bbe4-365fca868193        2048         2048   \n",
       "2    00537262-883c-4b37-a3a1-a4931b6faea5        2048         2048   \n",
       "3    00c9a1c9-2f06-476f-8b0d-6d01032874a2        2048         2048   \n",
       "4    0173029a-161d-40ef-af28-2342915b22fb        3072         3072   \n",
       "..                                    ...         ...          ...   \n",
       "554  fea47298-266a-4cf4-93bd-55d1bcc2fc7d        1728         1728   \n",
       "555  feb955db-6c07-4717-a98b-92236c8e01d8        2048         2048   \n",
       "556  fefb9bb7-934a-40d1-8d2f-210265857388        2048         2048   \n",
       "557  ff069fa2-d948-408e-91b3-034cfea428d1        3072         3072   \n",
       "558  ff23eea9-4bbe-42af-a8da-9ae16321fc6d        2048         2048   \n",
       "\n",
       "             PredictionString  \\\n",
       "0    0 1 eNoLCAgIMAEABJkBdQ==   \n",
       "1    0 1 eNoLCAgIMAEABJkBdQ==   \n",
       "2    0 1 eNoLCAgIMAEABJkBdQ==   \n",
       "3    0 1 eNoLCAgIMAEABJkBdQ==   \n",
       "4    0 1 eNoLCAgIsAQABJ4Beg==   \n",
       "..                        ...   \n",
       "554  0 1 eNoLCAjJNgIABNkBkg==   \n",
       "555  0 1 eNoLCAgIMAEABJkBdQ==   \n",
       "556  0 1 eNoLCAgIMAEABJkBdQ==   \n",
       "557  0 1 eNoLCAgIsAQABJ4Beg==   \n",
       "558  0 1 eNoLCAgIMAEABJkBdQ==   \n",
       "\n",
       "                                             mask_rles  \\\n",
       "0    [729089 8 729109 12 731137 8 731157 12 733185 ...   \n",
       "1    [557057 4 559105 4 561153 4 563201 4 565249 48...   \n",
       "2    [1 92 2049 92 4097 92 6145 92 8193 96 10241 96...   \n",
       "3    [1171605 16 1173653 16 1175701 16 1177749 16 1...   \n",
       "4    [1 558 3073 558 6145 558 9217 558 12289 558 15...   \n",
       "..                                                 ...   \n",
       "554  [2555936 17 2557664 17 2559392 17 2561090 64 2...   \n",
       "555  [1 456 597 184 2049 456 2645 184 4097 456 4693...   \n",
       "556  [1 332 2049 332 4097 332 6145 332 8193 332 102...   \n",
       "557  [2377891 60 2380963 60 2384035 60 2387107 60 2...   \n",
       "558  [1 268 349 80 2049 268 2397 80 4097 268 4445 8...   \n",
       "\n",
       "                                           mask_bboxes  \\\n",
       "0    [(356, 0, 1076, 244), (764, 0, 1456, 756), (15...   \n",
       "1    [(272, 0, 564, 196), (1648, 0, 2048, 260), (11...   \n",
       "2    [(0, 0, 304, 380), (712, 0, 1596, 384), (1772,...   \n",
       "3    [(572, 0, 1092, 264), (1512, 156, 2048, 684), ...   \n",
       "4    [(0, 0, 672, 624), (258, 0, 882, 318), (882, 0...   \n",
       "..                                                 ...   \n",
       "554  [(1479, 0, 1728, 341), (736, 31, 1367, 827), (...   \n",
       "555  [(0, 0, 216, 784), (208, 0, 796, 512), (640, 0...   \n",
       "556  [(0, 0, 496, 336), (672, 0, 1732, 680), (1516,...   \n",
       "557  [(774, 0, 1674, 402), (1338, 0, 2244, 810), (1...   \n",
       "558  [(0, 0, 244, 528), (180, 0, 504, 636), (728, 0...   \n",
       "\n",
       "                                         mask_sub_rles  \n",
       "0    [eNqtVL0OgyAQfiVIz4TBoYODiVdKE2odGDqYRi1p338rr...  \n",
       "1    [eNoLCAhINDDJyTc0AIMYwxQ/CCvBwAHCsPCA0DYuqDRcg...  \n",
       "2    [eNozyDEKyTU0AAMTHwOsACaOi7ZxQaUTDBwgjBjDFD80I...  \n",
       "3    [eNrFk7ESwiAMhl8puWNgYOjAwIAsou3AwNC7gvbO99/Ua...  \n",
       "4    [eNq9VMEKwjAM/aVQsE7ZRSgbCKVzh1mnVK1zjjH0/296c...  \n",
       "..                                                 ...  \n",
       "554  [eNqFUMEOgjAM/aU3tzijN02IIxtDEhJPgEajJ/3/m6xlM...  \n",
       "555  [eNrFlU2L2zAQQP+SJdvBh2XpLVmwFEEnmwkIOpQhGTeC/...  \n",
       "556  [eNoziLFKSTU0QAEmPgZkAR8T8uRh4oRoDwvSxAnZB9PnY...  \n",
       "557  [eNoLCk2KMMoxDMkzMoCBNL8gowh/ONcrycAFzonzz0Piu...  \n",
       "558  [eNq9ksFqwzAMhl8pauPNHTkMVmjxGkUwH3QwtQI+6OD3P...  \n",
       "\n",
       "[559 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define paths to nucleus and cell models for the cellsegmentator class\n",
    "NUC_MODEL = '/kaggle/input/hpacellsegmentatormodelweights/dpn_unet_nuclei_v1.pth'\n",
    "CELL_MODEL = '/kaggle/input/hpacellsegmentatormodelweights/dpn_unet_cell_3ch_v1.pth'\n",
    "\n",
    "CELL_CLSFR_DIR = \"/kaggle/input/hpa-cellwise-classification-training/resnet_b2_wdensehead/ckpt-0007-0.1082.ckpt\"\n",
    "\n",
    "# Define the path to the competition data directory\n",
    "DATA_DIR = \"/kaggle/input/hpa-single-cell-image-classification\"\n",
    "\n",
    "# Define the paths to the training and testing tfrecord and \n",
    "# image folders respectively for the competition data\n",
    "TEST_IMG_DIR = os.path.join(DATA_DIR, \"test\")\n",
    "\n",
    "# Capture all the relevant full image paths for the competition dataset\n",
    "TEST_IMG_PATHS = sorted([os.path.join(TEST_IMG_DIR, f_name) for f_name in os.listdir(TEST_IMG_DIR)])\n",
    "print(f\"... The number of testing images is {len(TEST_IMG_PATHS)}\" \\\n",
    "      f\"\\n\\t--> i.e. {len(TEST_IMG_PATHS)//4} 4-channel images ...\")\n",
    "\n",
    "# Define paths to the relevant csv files\n",
    "PUB_SS_CSV = \"/kaggle/input/hpa-sample-submission-with-extra-metadata/updated_sample_submission.csv\"\n",
    "SWAP_SS_CSV = os.path.join(DATA_DIR, \"sample_submission.csv\")\n",
    "\n",
    "# Create the relevant dataframe objects\n",
    "ss_df = pd.read_csv(SWAP_SS_CSV)\n",
    "\n",
    "# Test Time Augmentation Information\n",
    "DO_TTA = True\n",
    "TTA_REPEATS = 8\n",
    "\n",
    "# helps us control whether this is the full submission or just the initial pass\n",
    "IS_DEMO = len(ss_df)==559\n",
    "IS_DEMO = False\n",
    "if IS_DEMO:\n",
    "    #ss_df_1 = ss_df.drop_duplicates(\"ImageWidth\", keep=\"first\")\n",
    "    \n",
    "    #ss_df_2 = ss_df.drop_duplicates(\"ImageWidth\", keep=\"last\")\n",
    "    #ss_df = pd.concat([ss_df_1, ss_df_2])\n",
    "    #del ss_df_1; del ss_df_2; gc.collect();\n",
    "    print(\"\\n\\nSAMPLE SUBMISSION DATAFRAME\\n\\n\")\n",
    "    \n",
    "    display(ss_df)\n",
    "else:\n",
    "    print(\"\\n\\nSAMPLE SUBMISSION DATAFRAME1\\n\\n\")\n",
    "    display(ss_df)\n",
    "    \n",
    "# If demo-submission/display we only do a subset of the data\n",
    "if ONLY_PUBLIC:\n",
    "    pub_ss_df = pd.read_csv(PUB_SS_CSV)\n",
    "    \n",
    "    \n",
    "        \n",
    "    pub_ss_df.mask_rles = pub_ss_df.mask_rles.apply(lambda x: ast.literal_eval(x))\n",
    "    pub_ss_df.mask_bboxes = pub_ss_df.mask_bboxes.apply(lambda x: ast.literal_eval(x))\n",
    "    pub_ss_df.mask_sub_rles = pub_ss_df.mask_sub_rles.apply(lambda x: ast.literal_eval(x))\n",
    "    \n",
    "    print(\"\\n\\nTEST DATAFRAME W/ MASKS\\n\\n\")\n",
    "    display(pub_ss_df)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.02253,
     "end_time": "2021-05-06T18:32:33.042117",
     "exception": false,
     "start_time": "2021-05-06T18:32:33.019587",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a style=\"text-align: font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; color: navy; background-color: #ffffff;\" id=\"helper_functions\">3&nbsp;&nbsp;HELPER FUNCTIONS</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-05-06T18:32:33.120138Z",
     "iopub.status.busy": "2021-05-06T18:32:33.098809Z",
     "iopub.status.idle": "2021-05-06T18:32:33.183294Z",
     "shell.execute_reply": "2021-05-06T18:32:33.182749Z"
    },
    "papermill": {
     "duration": 0.118488,
     "end_time": "2021-05-06T18:32:33.183448",
     "exception": false,
     "start_time": "2021-05-06T18:32:33.064960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def binary_mask_to_ascii(mask, mask_val=1):\n",
    "    \"\"\"Converts a binary mask into OID challenge encoding ascii text.\"\"\"\n",
    "    mask = np.where(mask==mask_val, 1, 0).astype(np.bool)\n",
    "    \n",
    "    # check input mask --\n",
    "    if mask.dtype != np.bool:\n",
    "        raise ValueError(f\"encode_binary_mask expects a binary mask, received dtype == {mask.dtype}\")\n",
    "\n",
    "    mask = np.squeeze(mask)\n",
    "    if len(mask.shape) != 2:\n",
    "        raise ValueError(f\"encode_binary_mask expects a 2d mask, received shape == {mask.shape}\")\n",
    "\n",
    "    # convert input mask to expected COCO API input --\n",
    "    mask_to_encode = mask.reshape(mask.shape[0], mask.shape[1], 1)\n",
    "    mask_to_encode = mask_to_encode.astype(np.uint8)\n",
    "    mask_to_encode = np.asfortranarray(mask_to_encode)\n",
    "\n",
    "    # RLE encode mask --\n",
    "    encoded_mask = coco_mask.encode(mask_to_encode)[0][\"counts\"]\n",
    "\n",
    "    # compress and base64 encoding --\n",
    "    binary_str = zlib.compress(encoded_mask, zlib.Z_BEST_COMPRESSION)\n",
    "    base64_str = base64.b64encode(binary_str)\n",
    "    return base64_str.decode()\n",
    "\n",
    "\n",
    "def rle_encoding(img, mask_val=1):\n",
    "    \"\"\"\n",
    "    Turns our masks into RLE encoding to easily store them\n",
    "    and feed them into models later on\n",
    "    https://en.wikipedia.org/wiki/Run-length_encoding\n",
    "    \n",
    "    Args:\n",
    "        img (np.array): Segmentation array\n",
    "        mask_val (int): Which value to use to create the RLE\n",
    "        \n",
    "    Returns:\n",
    "        RLE string\n",
    "    \n",
    "    \"\"\"\n",
    "    dots = np.where(img.T.flatten() == mask_val)[0]\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if (b>prev+1): run_lengths.extend((b + 1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "        \n",
    "    return ' '.join([str(x) for x in run_lengths])\n",
    "\n",
    "\n",
    "def rle_to_mask(rle_string, height, width):\n",
    "    \"\"\" Convert RLE sttring into a binary mask \n",
    "    \n",
    "    Args:\n",
    "        rle_string (rle_string): Run length encoding containing \n",
    "            segmentation mask information\n",
    "        height (int): Height of the original image the map comes from\n",
    "        width (int): Width of the original image the map comes from\n",
    "    \n",
    "    Returns:\n",
    "        Numpy array of the binary segmentation mask for a given cell\n",
    "    \"\"\"\n",
    "    rows,cols = height,width\n",
    "    rle_numbers = [int(num_string) for num_string in rle_string.split(' ')]\n",
    "    rle_pairs = np.array(rle_numbers).reshape(-1,2)\n",
    "    img = np.zeros(rows*cols,dtype=np.uint8)\n",
    "    for index,length in rle_pairs:\n",
    "        index -= 1\n",
    "        img[index:index+length] = 255\n",
    "    img = img.reshape(cols,rows)\n",
    "    img = img.T\n",
    "    return img\n",
    "\n",
    "\n",
    "def decode_img(img, img_size=(224,224), testing=False):\n",
    "    \"\"\"TBD\"\"\"\n",
    "    \n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    if not testing:\n",
    "        # resize the image to the desired size\n",
    "        img = tf.image.decode_png(img, channels=1)\n",
    "        return tf.cast(tf.image.resize(img, img_size), tf.uint8)\n",
    "    else:\n",
    "        return tf.image.decode_png(img, channels=1)\n",
    "        \n",
    "\n",
    "    \n",
    "def preprocess_path_ds(rp, gp, bp, yp, lbl, n_classes=19, img_size=(224,224), combine=True, drop_yellow=True):\n",
    "    \"\"\" TBD \"\"\"\n",
    "    \n",
    "    ri = decode_img(tf.io.read_file(rp), img_size)\n",
    "    gi = decode_img(tf.io.read_file(gp), img_size)\n",
    "    bi = decode_img(tf.io.read_file(bp), img_size)\n",
    "    yi = decode_img(tf.io.read_file(yp), img_size)\n",
    "\n",
    "    if combine and drop_yellow:\n",
    "        return tf.stack([ri[..., 0], gi[..., 0], bi[..., 0]], axis=-1), tf.one_hot(lbl, n_classes, dtype=tf.uint8)\n",
    "    elif combine:\n",
    "        return tf.stack([ri[..., 0], gi[..., 0], bi[..., 0], yi[..., 0]], axis=-1), tf.one_hot(lbl, n_classes, dtype=tf.uint8)\n",
    "    elif drop_yellow:\n",
    "        return ri, gi, bi, tf.one_hot(lbl, n_classes, dtype=tf.uint8)\n",
    "    else:\n",
    "        return ri, gi, bi, yi, tf.one_hot(lbl, n_classes, dtype=tf.uint8)        \n",
    "    \n",
    "    \n",
    "def create_pred_col(row):\n",
    "    \"\"\" Simple function to return the correct prediction string\n",
    "    \n",
    "    We will want the original public test dataframe submission when it is \n",
    "    available. However, we will use the swapped inn submission dataframe\n",
    "    when it is not.\n",
    "    \n",
    "    Args:\n",
    "        row (pd.Series): A row in the dataframe\n",
    "    \n",
    "    Returns:\n",
    "        The prediction string\n",
    "    \"\"\"\n",
    "    if pd.isnull(row.PredictionString_y):\n",
    "        return row.PredictionString_x\n",
    "    else:\n",
    "        return row.PredictionString_y\n",
    "    \n",
    "    \n",
    "def load_image(img_id, img_dir, testing=False, only_public=False):\n",
    "    \"\"\" Load An Image Using ID and Directory Path - Composes 4 Individual Images \"\"\"\n",
    "    if only_public:\n",
    "        return_axis = -1\n",
    "        clr_list = [\"red\", \"green\", \"blue\"]\n",
    "    else:\n",
    "        return_axis = 0\n",
    "        clr_list = [\"red\", \"green\", \"blue\", \"yellow\"]\n",
    "    \n",
    "    if not testing:\n",
    "        rgby = [\n",
    "            np.asarray(Image.open(os.path.join(img_dir, img_id+f\"_{c}.png\")), np.uint8) \\\n",
    "            for c in [\"red\", \"green\", \"blue\", \"yellow\"]\n",
    "        ]\n",
    "        return np.stack(rgby, axis=-1)\n",
    "    else:\n",
    "        # This is for cellsegmentator\n",
    "        return np.stack(\n",
    "            [np.asarray(decode_img(tf.io.read_file(os.path.join(img_dir, img_id+f\"_{c}.png\")), testing=True), np.uint8)[..., 0] \\\n",
    "             for c in clr_list], axis=return_axis,\n",
    "        )\n",
    "        \n",
    "\n",
    "\n",
    "def plot_rgb(arr, figsize=(12,12)):\n",
    "    \"\"\" Plot 3 Channel Microscopy Image \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.title(f\"RGB Composite Image\", fontweight=\"bold\")\n",
    "    plt.imshow(arr)\n",
    "    plt.axis(False)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def convert_rgby_to_rgb(arr):\n",
    "    \"\"\" Convert a 4 channel (RGBY) image to a 3 channel RGB image.\n",
    "    \n",
    "    Advice From Competition Host/User: lnhtrang\n",
    "\n",
    "    For annotation (by experts) and for the model, I guess we agree that individual \n",
    "    channels with full range px values are better. \n",
    "    In annotation, we toggled the channels. \n",
    "    For visualization purpose only, you can try blending the channels. \n",
    "    For example, \n",
    "        - red = red + yellow\n",
    "        - green = green + yellow/2\n",
    "        - blue=blue.\n",
    "        \n",
    "    Args:\n",
    "        arr (numpy array): The RGBY, 4 channel numpy array for a given image\n",
    "    \n",
    "    Returns:\n",
    "        RGB Image\n",
    "    \"\"\"\n",
    "    \n",
    "    rgb_arr = np.zeros_like(arr[..., :-1])\n",
    "    rgb_arr[..., 0] = arr[..., 0]\n",
    "    rgb_arr[..., 1] = arr[..., 1]+arr[..., 3]/2\n",
    "    rgb_arr[..., 2] = arr[..., 2]\n",
    "    \n",
    "    return rgb_arr\n",
    "    \n",
    "    \n",
    "def plot_ex(arr, figsize=(20,6), title=None, plot_merged=True, rgb_only=False):\n",
    "    \"\"\" Plot 4 Channels Side by Side \"\"\"\n",
    "    if plot_merged and not rgb_only:\n",
    "        n_images=5 \n",
    "    elif plot_merged and rgb_only:\n",
    "        n_images=4\n",
    "    elif not plot_merged and rgb_only:\n",
    "        n_images=4\n",
    "    else:\n",
    "        n_images=3\n",
    "    plt.figure(figsize=figsize)\n",
    "    if type(title) == str:\n",
    "        plt.suptitle(title, fontsize=20, fontweight=\"bold\")\n",
    "\n",
    "    for i, c in enumerate([\"Red Channel – Microtubles\", \"Green Channel – Protein of Interest\", \"Blue - Nucleus\", \"Yellow – Endoplasmic Reticulum\"]):\n",
    "        if not rgb_only:\n",
    "            ch_arr = np.zeros_like(arr[..., :-1])        \n",
    "        else:\n",
    "            ch_arr = np.zeros_like(arr)\n",
    "        if c in [\"Red Channel – Microtubles\", \"Green Channel – Protein of Interest\", \"Blue - Nucleus\"]:\n",
    "            ch_arr[..., i] = arr[..., i]\n",
    "        else:\n",
    "            if rgb_only:\n",
    "                continue\n",
    "            ch_arr[..., 0] = arr[..., i]\n",
    "            ch_arr[..., 1] = arr[..., i]\n",
    "        plt.subplot(1,n_images,i+1)\n",
    "        plt.title(f\"{c.title()}\", fontweight=\"bold\")\n",
    "        plt.imshow(ch_arr)\n",
    "        plt.axis(False)\n",
    "        \n",
    "    if plot_merged:\n",
    "        plt.subplot(1,n_images,n_images)\n",
    "        \n",
    "        if rgb_only:\n",
    "            plt.title(f\"Merged RGB\", fontweight=\"bold\")\n",
    "            plt.imshow(arr)\n",
    "        else:\n",
    "            plt.title(f\"Merged RGBY into RGB\", fontweight=\"bold\")\n",
    "            plt.imshow(convert_rgby_to_rgb(arr))\n",
    "        plt.axis(False)\n",
    "        \n",
    "    plt.tight_layout(rect=[0, 0.2, 1, 0.97])\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def flatten_list_of_lists(l_o_l, to_string=False):\n",
    "    if not to_string:\n",
    "        return [item for sublist in l_o_l for item in sublist]\n",
    "    else:\n",
    "        return [str(item) for sublist in l_o_l for item in sublist]\n",
    "\n",
    "\n",
    "def create_segmentation_maps(list_of_image_lists, segmentator, batch_size=8):\n",
    "    \"\"\" Function to generate segmentation maps using CellSegmentator tool \n",
    "    \n",
    "    Args:\n",
    "        list_of_image_lists (list of lists):\n",
    "            - [[micro-tubules(red)], [endoplasmic-reticulum(yellow)], [nucleus(blue)]]\n",
    "        batch_size (int): Batch size to use in generating the segmentation masks\n",
    "        \n",
    "    Returns:\n",
    "        List of lists containing RLEs for all the cells in all images\n",
    "    \"\"\"\n",
    "    \n",
    "    all_mask_rles = {}\n",
    "    for i in tqdm(range(0, len(list_of_image_lists[0]), batch_size), total=len(list_of_image_lists[0])//batch_size):\n",
    "        \n",
    "        # Get batch of images\n",
    "        sub_images = [img_channel_list[i:i+batch_size] for img_channel_list in list_of_image_lists] # 0.000001 seconds\n",
    "\n",
    "        # Do segmentation\n",
    "        cell_segmentations = segmentator.pred_cells(sub_images)\n",
    "        nuc_segmentations = segmentator.pred_nuclei(sub_images[2])\n",
    "\n",
    "        # post-processing\n",
    "        for j, path in enumerate(sub_images[0]):\n",
    "            img_id = path.replace(\"_red.png\", \"\").rsplit(\"/\", 1)[1]\n",
    "            nuc_mask, cell_mask = label_cell(nuc_segmentations[j], cell_segmentations[j])\n",
    "            new_name = os.path.basename(path).replace('red','mask')\n",
    "            all_mask_rles[img_id] = [rle_encoding(cell_mask, mask_val=k) for k in range(1, np.max(cell_mask)+1)]\n",
    "    return all_mask_rles\n",
    "\n",
    "\n",
    "def get_img_list(img_dir, return_ids=False, sub_n=None):\n",
    "    \"\"\" Get image list in the format expected by the CellSegmentator tool \"\"\"\n",
    "    if sub_n is None:\n",
    "        sub_n=len(glob(img_dir + '/' + f'*_red.png'))\n",
    "    if return_ids:\n",
    "        images = [sorted(glob(img_dir + '/' + f'*_{c}.png'))[:sub_n] for c in [\"red\", \"yellow\", \"blue\"]]\n",
    "        return [x.replace(\"_red.png\", \"\").rsplit(\"/\", 1)[1] for x in images[0]], images\n",
    "    else:\n",
    "        return [sorted(glob(img_dir + '/' + f'*_{c}.png'))[:sub_n] for c in [\"red\", \"yellow\", \"blue\"]]\n",
    "    \n",
    "    \n",
    "def get_contour_bbox_from_rle(rle, width, height, return_mask=True,):\n",
    "    \"\"\" Get bbox of contour as `xmin ymin xmax ymax`\n",
    "    \n",
    "    Args:\n",
    "        rle (rle_string): Run length encoding containing \n",
    "            segmentation mask information\n",
    "        height (int): Height of the original image the map comes from\n",
    "        width (int): Width of the original image the map comes from\n",
    "    \n",
    "    Returns:\n",
    "        Numpy array for a cell bounding box coordinates\n",
    "    \"\"\"\n",
    "    mask = rle_to_mask(rle, height, width).copy()\n",
    "    cnts = grab_contours(\n",
    "        cv2.findContours(\n",
    "            mask, \n",
    "            cv2.RETR_EXTERNAL, \n",
    "            cv2.CHAIN_APPROX_SIMPLE\n",
    "        ))\n",
    "    x,y,w,h = cv2.boundingRect(cnts[0])\n",
    "    \n",
    "    if return_mask:\n",
    "        return (x,y,x+w,y+h), mask\n",
    "    else:\n",
    "        return (x,y,x+w,y+h)\n",
    "    \n",
    "\n",
    "def get_contour_bbox_from_raw(raw_mask):\n",
    "    \"\"\" Get bbox of contour as `xmin ymin xmax ymax`\n",
    "    \n",
    "    Args:\n",
    "        raw_mask (nparray): Numpy array containing segmentation mask information\n",
    "    \n",
    "    Returns:\n",
    "        Numpy array for a cell bounding box coordinates\n",
    "    \"\"\"\n",
    "    cnts = grab_contours(\n",
    "        cv2.findContours(\n",
    "            raw_mask, \n",
    "            cv2.RETR_EXTERNAL, \n",
    "            cv2.CHAIN_APPROX_SIMPLE\n",
    "        ))\n",
    "    xywhs = [cv2.boundingRect(cnt) for cnt in cnts]\n",
    "    xys = [(xywh[0], xywh[1], xywh[0]+xywh[2], xywh[1]+xywh[3]) for xywh in xywhs]\n",
    "    return sorted(xys, key=lambda x: (x[1], x[0]))\n",
    "\n",
    "\n",
    "def pad_to_square(a):\n",
    "    \"\"\" Pad an array `a` evenly until it is a square \"\"\"\n",
    "    if a.shape[1]>a.shape[0]: # pad height\n",
    "        n_to_add = a.shape[1]-a.shape[0]\n",
    "        top_pad = n_to_add//2\n",
    "        bottom_pad = n_to_add-top_pad\n",
    "        a = np.pad(a, [(top_pad, bottom_pad), (0, 0), (0, 0)], mode='constant')\n",
    "\n",
    "    elif a.shape[0]>a.shape[1]: # pad width\n",
    "        n_to_add = a.shape[0]-a.shape[1]\n",
    "        left_pad = n_to_add//2\n",
    "        right_pad = n_to_add-left_pad\n",
    "        a = np.pad(a, [(0, 0), (left_pad, right_pad), (0, 0)], mode='constant')\n",
    "    else:\n",
    "        pass\n",
    "    return a\n",
    "\n",
    "\n",
    "def cut_out_cells(rgby, rles, resize_to=(256,256), square_off=True, return_masks=False, from_raw=True):\n",
    "    \"\"\" Cut out the cells as padded square images \n",
    "    \n",
    "    Args:\n",
    "        rgby (np.array): 4 Channel image to be cut into tiles\n",
    "        rles (list of RLE strings): List of run length encoding containing \n",
    "            segmentation mask information\n",
    "        resize_to (tuple of ints, optional): The square dimension to resize the image to\n",
    "        square_off (bool, optional): Whether to pad the image to a square or not\n",
    "        \n",
    "    Returns:\n",
    "        list of square arrays representing squared off cell images\n",
    "    \"\"\"\n",
    "    w,h = rgby.shape[:2]\n",
    "    contour_bboxes = [get_contour_bbox(rle, w, h, return_mask=return_masks) for rle in rles]\n",
    "    if return_masks:\n",
    "        masks = [x[-1] for x in contour_bboxes]\n",
    "        contour_bboxes = [x[:-1] for x in contour_bboxes]\n",
    "    \n",
    "    arrs = [rgby[bbox[1]:bbox[3], bbox[0]:bbox[2], ...] for bbox in contour_bboxes]\n",
    "    if square_off:\n",
    "        arrs = [pad_to_square(arr) for arr in arrs]\n",
    "        \n",
    "    if resize_to is not None:\n",
    "        arrs = [\n",
    "            cv2.resize(pad_to_square(arr).astype(np.float32), \n",
    "                       resize_to, \n",
    "                       interpolation=cv2.INTER_CUBIC) \\\n",
    "            for arr in arrs\n",
    "        ]\n",
    "    if return_masks:\n",
    "        return arrs, masks\n",
    "    else:\n",
    "        return arrs\n",
    "\n",
    "\n",
    "def grab_contours(cnts):\n",
    "    # if the length the contours tuple returned by cv2.findContours\n",
    "    # is '2' then we are using either OpenCV v2.4, v4-beta, or\n",
    "    # v4-official\n",
    "    if len(cnts) == 2:\n",
    "        cnts = cnts[0]\n",
    "\n",
    "    # if the length of the contours tuple is '3' then we are using\n",
    "    # either OpenCV v3, v4-pre, or v4-alpha\n",
    "    elif len(cnts) == 3:\n",
    "        cnts = cnts[1]\n",
    "\n",
    "    # otherwise OpenCV has changed their cv2.findContours return\n",
    "    # signature yet again and I have no idea WTH is going on\n",
    "    else:\n",
    "        raise Exception((\"Contours tuple must have length 2 or 3, \"\n",
    "            \"otherwise OpenCV changed their cv2.findContours return \"\n",
    "            \"signature yet again. Refer to OpenCV's documentation \"\n",
    "            \"in that case\"))\n",
    "\n",
    "    # return the actual contours array\n",
    "    return cnts\n",
    "\n",
    "\n",
    "def preprocess_row(img_id, img_w, img_h, combine=True, drop_yellow=True):\n",
    "    \"\"\" TBD \"\"\"\n",
    "\n",
    "    rp = os.path.join(TEST_IMG_DIR, img_id+\"_red.png\")\n",
    "    gp = os.path.join(TEST_IMG_DIR, img_id+\"_green.png\")\n",
    "    bp = os.path.join(TEST_IMG_DIR, img_id+\"_blue.png\")\n",
    "    yp = os.path.join(TEST_IMG_DIR, img_id+\"_yellow.png\")\n",
    "    \n",
    "    ri = decode_img(tf.io.read_file(rp), (img_w, img_h), testing=True)\n",
    "    gi = decode_img(tf.io.read_file(gp), (img_w, img_h), testing=True)\n",
    "    bi = decode_img(tf.io.read_file(bp), (img_w, img_h), testing=True)\n",
    "\n",
    "    if not drop_yellow:\n",
    "        yi = decode_img(tf.io.read_file(yp), (img_w, img_h), testing=True)\n",
    "\n",
    "    if combine and drop_yellow:\n",
    "        return tf.stack([ri[..., 0], gi[..., 0], bi[..., 0]], axis=-1)\n",
    "    elif combine:\n",
    "        return tf.stack([ri[..., 0], gi[..., 0], bi[..., 0], yi[..., 0]], axis=-1)\n",
    "    elif drop_yellow:\n",
    "        return ri, gi, bi\n",
    "    else:\n",
    "        return ri, gi, bi, yi\n",
    "\n",
    "    \n",
    "def plot_predictions(img, masks, preds, confs=None, fill_alpha=0.3, lbl_as_str=True):\n",
    "    # Initialize\n",
    "    FONT = cv2.FONT_HERSHEY_SIMPLEX; FONT_SCALE = 0.7; FONT_THICKNESS = 2; FONT_LINE_TYPE = cv2.LINE_AA;\n",
    "    COLORS = [[round(y*255) for y in x] for x in sns.color_palette(\"Spectral\", len(LBL_NAMES))]\n",
    "    to_plot = img.copy()\n",
    "    cntr_img = img.copy()\n",
    "    if confs==None:\n",
    "        confs = [None,]*len(masks)\n",
    "\n",
    "    cnts = grab_contours(\n",
    "        cv2.findContours(\n",
    "            masks, \n",
    "            cv2.RETR_EXTERNAL, \n",
    "            cv2.CHAIN_APPROX_SIMPLE\n",
    "        ))\n",
    "    cnts = sorted(cnts, key=lambda x: (cv2.boundingRect(x)[1], cv2.boundingRect(x)[0]))\n",
    "        \n",
    "    for c, pred, conf in zip(cnts, preds, confs):\n",
    "        # We can only display one color so we pick the first\n",
    "        color = COLORS[pred[0]]\n",
    "        if not lbl_as_str:\n",
    "            classes = \"CLS=[\"+\",\".join([str(p) for p in pred])+\"]\"\n",
    "        else:\n",
    "            classes = \", \".join([INT_2_STR[p] for p in pred])\n",
    "        M = cv2.moments(c)\n",
    "        cx = int(M['m10']/M['m00'])\n",
    "        cy = int(M['m01']/M['m00'])\n",
    "        \n",
    "        text_width, text_height = cv2.getTextSize(classes, FONT, FONT_SCALE, FONT_THICKNESS)[0]\n",
    "        \n",
    "        # Border and fill\n",
    "        cv2.drawContours(to_plot, [c], contourIdx=-1, color=[max(0, x-40) for x in color], thickness=10)\n",
    "        cv2.drawContours(cntr_img, [c], contourIdx=-1, color=(color), thickness=-1)\n",
    "        \n",
    "        # Text\n",
    "        cv2.putText(to_plot, classes, (cx-text_width//2,cy-text_height//2),\n",
    "                    FONT, FONT_SCALE, [min(255, x+40) for x in color], FONT_THICKNESS, FONT_LINE_TYPE)\n",
    "    \n",
    "    cv2.addWeighted(cntr_img, fill_alpha, to_plot, 1-fill_alpha, 0, to_plot)\n",
    "    #plt.figure(figsize=(16,16))\n",
    "    #plt.imshow(to_plot)\n",
    "    #plt.axis(False)\n",
    "    #plt.show()\n",
    "    \n",
    "def tta(original_img_batch, repeats=4):\n",
    "    \"\"\" Perform test time augmentation \"\"\"\n",
    "    tta_img_batches = [original_img_batch,]\n",
    "\n",
    "    for i in range(repeats):\n",
    "        # create new image batch (tf automatically deep copies)\n",
    "        img_batch = original_img_batch\n",
    "        \n",
    "        SEED = tf.random.uniform((2,), minval=0, maxval=100, dtype=tf.dtypes.int32)\n",
    "        K = tf.random.uniform((1,), minval=0, maxval=4, dtype=tf.dtypes.int32)[0]\n",
    "\n",
    "        img_batch = tf.image.stateless_random_flip_left_right(img_batch, SEED)\n",
    "        img_batch = tf.image.stateless_random_flip_up_down(img_batch, SEED)\n",
    "        img_batch = tf.image.rot90(img_batch, K)\n",
    "\n",
    "        img_batch = tf.image.stateless_random_saturation(img_batch, 0.9, 1.1, SEED)\n",
    "        img_batch = tf.image.stateless_random_brightness(img_batch, 0.075, SEED)\n",
    "        img_batch = tf.image.stateless_random_contrast(img_batch, 0.9, 1.1, SEED)    \n",
    "        tta_img_batches.append(img_batch)\n",
    "    \n",
    "    return tta_img_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.02258,
     "end_time": "2021-05-06T18:32:33.229063",
     "exception": false,
     "start_time": "2021-05-06T18:32:33.206483",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a style=\"text-align: font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; color: navy; background-color: #ffffff;\" id=\"inference\">4&nbsp;&nbsp;INFERENCE LOOP</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022378,
     "end_time": "2021-05-06T18:32:33.274371",
     "exception": false,
     "start_time": "2021-05-06T18:32:33.251993",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-06T18:32:33.335128Z",
     "iopub.status.busy": "2021-05-06T18:32:33.334193Z",
     "iopub.status.idle": "2021-05-06T18:32:51.320083Z",
     "shell.execute_reply": "2021-05-06T18:32:51.319304Z"
    },
    "papermill": {
     "duration": 18.023166,
     "end_time": "2021-05-06T18:32:51.320246",
     "exception": false,
     "start_time": "2021-05-06T18:32:33.297080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load inference model\n",
    "inference_model = tf.keras.models.load_model(CELL_CLSFR_DIR)\n",
    "\n",
    "# Parameters\n",
    "IMAGE_SIZES = [1728, 2048, 3072, 4096]\n",
    "BATCH_SIZE = 8\n",
    "CONF_THRESH = 0.0\n",
    "TILE_SIZE = (224,224)\n",
    "\n",
    "\n",
    "# Switch what we will be actually infering on\n",
    "if ONLY_PUBLIC:\n",
    "    # Make subset dataframes\n",
    "    predict_df_1728 = pub_ss_df[pub_ss_df.ImageWidth==IMAGE_SIZES[0]]\n",
    "    predict_df_2048 = pub_ss_df[pub_ss_df.ImageWidth==IMAGE_SIZES[1]]\n",
    "    predict_df_3072 = pub_ss_df[pub_ss_df.ImageWidth==IMAGE_SIZES[2]]\n",
    "    predict_df_4096 = pub_ss_df[pub_ss_df.ImageWidth==IMAGE_SIZES[3]]\n",
    "else:\n",
    "    # Load Segmentator\n",
    "    segmentator = cellsegmentator.CellSegmentator(NUC_MODEL, CELL_MODEL, scale_factor=0.275, padding=True)\n",
    "    \n",
    "    # Make subset dataframes\n",
    "    predict_df_1728 = ss_df[ss_df.ImageWidth==IMAGE_SIZES[0]]\n",
    "    predict_df_2048 = ss_df[ss_df.ImageWidth==IMAGE_SIZES[1]]\n",
    "    predict_df_3072 = ss_df[ss_df.ImageWidth==IMAGE_SIZES[2]]\n",
    "    predict_df_4096 = ss_df[ss_df.ImageWidth==IMAGE_SIZES[3]]\n",
    "\n",
    "\n",
    "predict_ids_1728 = predict_df_1728.ID.to_list()\n",
    "#print(predict_ids_1728)\n",
    "predict_ids_2048 = predict_df_2048.ID.to_list()\n",
    "predict_ids_3072 = predict_df_3072.ID.to_list()\n",
    "predict_ids_4096 = predict_df_4096.ID.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024113,
     "end_time": "2021-05-06T18:32:51.368141",
     "exception": false,
     "start_time": "2021-05-06T18:32:51.344028",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h3 style=\"text-align: font-family: Verdana; font-size: 20px; font-style: normal; font-weight: normal; text-decoration: none; text-transform: none; letter-spacing: 2px; color: navy; background-color: #ffffff;\">4.2 INFER</h3>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-06T18:32:51.443767Z",
     "iopub.status.busy": "2021-05-06T18:32:51.434228Z",
     "iopub.status.idle": "2021-05-06T21:24:39.579820Z",
     "shell.execute_reply": "2021-05-06T21:24:39.575310Z"
    },
    "papermill": {
     "duration": 10308.188919,
     "end_time": "2021-05-06T21:24:39.580128",
     "exception": false,
     "start_time": "2021-05-06T18:32:51.391209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...WORKING ON IMAGE IDS FOR SIZE 1728 ...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b430a6b1ae0749cfbe48602db0d93709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...WORKING ON IMAGE IDS FOR SIZE 2048 ...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f886556b8924afc9b588efce6a8d515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...WORKING ON IMAGE IDS FOR SIZE 3072 ...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f1ed1ed69cd4812b6cd2c8e607c030e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...SKIPPING SIZE 4096 AS THERE ARE NO IMAGE IDS ...\n",
      "\n",
      "\n",
      "... TEST DATAFRAME ...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>020a29cf-2c24-478b-8603-c22a90dc3e31</td>\n",
       "      <td>0 0.0010 eNq1lltvqzAMgP8SDtmZtKcjHWlSN+KulG3QJ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02b3c5aa-d70c-49d1-b3e5-3f5cc10375ca</td>\n",
       "      <td>0 0.0008 eNozSDWKTjY0wAKMfTHFTHwQMjB5iJiVG4SXY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02f9ee97-bf2e-4d9d-bdfd-b903ec2e79c0</td>\n",
       "      <td>0 0.0001 eNrFlc2SgjAMgF/JDBbF2eviwmimKvWvIAh10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0c57f7f4-c9b9-4824-aa0e-c98bd8860434</td>\n",
       "      <td>0 0.9811 eNqLTM7OM8wwiEg1NDAw8LV1MwADc08QaeYFJ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0e498bec-8155-4f31-9a23-8ebc5efe9dd7</td>\n",
       "      <td>0 0.0015 eNp9UtFSgzAQ/KU7w8jIo8501IHLgGBn2iaYj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0ec42e43-bb66-41a0-bd95-d143d10ca78a</td>\n",
       "      <td>0 0.0000 eNqFVG1Pg0AM/kslJaAkc4ZFJssdyJLNZC4xW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0f0b6d5d-642d-4d63-97ee-dcf4b2a9203e</td>\n",
       "      <td>0 0.1979 eNq1lmt3okgQhv9Sl0DMZM7mzGbOZKNAN6AiC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>182bc913-abca-46a9-b5fa-416ea862d655</td>\n",
       "      <td>0 0.0002 eNqtk9tygyAQhl+JHZzamulNO9OpCpjmYI1KP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1de83a24-4043-4367-9cfc-735e5d5f40fd</td>\n",
       "      <td>0 0.2679 eNqFlF93myAUwL8SN7C6Y0/3sJ21SyM429h5K...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>22fa496b-f407-4df0-96ed-8942df0bcd9d</td>\n",
       "      <td>0 0.0004 eNqlltuWojgUhl+JDExVN2L3ajE9ywJTcjIoC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2990b07d-701b-430b-b00d-abe4e8beb60c</td>\n",
       "      <td>0 0.6173 eNq1lVtvozAQhf/SDK3UBKS+JEq3K2KTEgg4p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2dd34a23-84bb-4849-a285-cb60fb40ac47</td>\n",
       "      <td>0 0.0001 eNqdU8FygjAQ/aWEWK3U9iBTHRkSRquSioABF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3011d306-da16-43c5-9c7a-46953c4e5a32</td>\n",
       "      <td>0 0.0024 eNqllF2TgiAUhv8S+G17vZpNgVYqrkzmRFlq+...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>33658e9c-d07d-46c5-b5ec-046338509a3e</td>\n",
       "      <td>0 0.0257 eNqNUU0LwjAM/UuvbCDoTbAw2KYHYQilOpgfO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>33932b91-1844-42f7-9363-90f72dae37a4</td>\n",
       "      <td>0 0.0012 eNqFVG1vgjAQ/kseZRJZlixZwsBA56pTdEALy...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      ID  \\\n",
       "0   020a29cf-2c24-478b-8603-c22a90dc3e31   \n",
       "1   02b3c5aa-d70c-49d1-b3e5-3f5cc10375ca   \n",
       "2   02f9ee97-bf2e-4d9d-bdfd-b903ec2e79c0   \n",
       "3   0c57f7f4-c9b9-4824-aa0e-c98bd8860434   \n",
       "4   0e498bec-8155-4f31-9a23-8ebc5efe9dd7   \n",
       "5   0ec42e43-bb66-41a0-bd95-d143d10ca78a   \n",
       "6   0f0b6d5d-642d-4d63-97ee-dcf4b2a9203e   \n",
       "7   182bc913-abca-46a9-b5fa-416ea862d655   \n",
       "8   1de83a24-4043-4367-9cfc-735e5d5f40fd   \n",
       "9   22fa496b-f407-4df0-96ed-8942df0bcd9d   \n",
       "10  2990b07d-701b-430b-b00d-abe4e8beb60c   \n",
       "11  2dd34a23-84bb-4849-a285-cb60fb40ac47   \n",
       "12  3011d306-da16-43c5-9c7a-46953c4e5a32   \n",
       "13  33658e9c-d07d-46c5-b5ec-046338509a3e   \n",
       "14  33932b91-1844-42f7-9363-90f72dae37a4   \n",
       "\n",
       "                                     PredictionString  \n",
       "0   0 0.0010 eNq1lltvqzAMgP8SDtmZtKcjHWlSN+KulG3QJ...  \n",
       "1   0 0.0008 eNozSDWKTjY0wAKMfTHFTHwQMjB5iJiVG4SXY...  \n",
       "2   0 0.0001 eNrFlc2SgjAMgF/JDBbF2eviwmimKvWvIAh10...  \n",
       "3   0 0.9811 eNqLTM7OM8wwiEg1NDAw8LV1MwADc08QaeYFJ...  \n",
       "4   0 0.0015 eNp9UtFSgzAQ/KU7w8jIo8501IHLgGBn2iaYj...  \n",
       "5   0 0.0000 eNqFVG1Pg0AM/kslJaAkc4ZFJssdyJLNZC4xW...  \n",
       "6   0 0.1979 eNq1lmt3okgQhv9Sl0DMZM7mzGbOZKNAN6AiC...  \n",
       "7   0 0.0002 eNqtk9tygyAQhl+JHZzamulNO9OpCpjmYI1KP...  \n",
       "8   0 0.2679 eNqFlF93myAUwL8SN7C6Y0/3sJ21SyM429h5K...  \n",
       "9   0 0.0004 eNqlltuWojgUhl+JDExVN2L3ajE9ywJTcjIoC...  \n",
       "10  0 0.6173 eNq1lVtvozAQhf/SDK3UBKS+JEq3K2KTEgg4p...  \n",
       "11  0 0.0001 eNqdU8FygjAQ/aWEWK3U9iBTHRkSRquSioABF...  \n",
       "12  0 0.0024 eNqllF2TgiAUhv8S+G17vZpNgVYqrkzmRFlq+...  \n",
       "13  0 0.0257 eNqNUU0LwjAM/UuvbCDoTbAw2KYHYQilOpgfO...  \n",
       "14  0 0.0012 eNqFVG1vgjAQ/kseZRJZlixZwsBA56pTdEALy...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = []\n",
    "sub_df = pd.DataFrame(columns=[\"ID\"], data=predict_ids_1728+predict_ids_2048+predict_ids_3072+predict_ids_4096)\n",
    "\n",
    "for size_idx, submission_ids in enumerate([predict_ids_1728, predict_ids_2048, predict_ids_3072, predict_ids_4096]):\n",
    "    size = IMAGE_SIZES[size_idx]\n",
    "    if submission_ids==[]:\n",
    "        print(f\"\\n...SKIPPING SIZE {size} AS THERE ARE NO IMAGE IDS ...\\n\")\n",
    "        continue\n",
    "    else:\n",
    "        print(f\"\\n...WORKING ON IMAGE IDS FOR SIZE {size} ...\\n\")\n",
    "    for i in tqdm(range(0, len(submission_ids), BATCH_SIZE), total=int(np.ceil(len(submission_ids)/BATCH_SIZE))):\n",
    "        \n",
    "        # Step 0: Get batch of images as numpy arrays\n",
    "        batch_rgby_images = [\n",
    "            load_image(ID, TEST_IMG_DIR, testing=True, only_public=ONLY_PUBLIC) \\\n",
    "            for ID in submission_ids[i:(i+BATCH_SIZE)]\n",
    "        ]\n",
    "        \n",
    "        if ONLY_PUBLIC:\n",
    "            # Step 1: Get Bounding Boxes\n",
    "            batch_cell_bboxes = pub_ss_df[pub_ss_df.ID.isin(submission_ids[i:(i+BATCH_SIZE)])].mask_bboxes.values\n",
    "            \n",
    "            # Step 2: Get RGB Images (which are actually just labelled as RGBY)\n",
    "            batch_rgb_images = batch_rgby_images\n",
    "            \n",
    "            # Step 3: Get Submission RLEs\n",
    "            submission_rles = pub_ss_df[pub_ss_df.ID.isin(submission_ids[i:(i+BATCH_SIZE)])].mask_sub_rles.values\n",
    "            \n",
    "            # Optional Step: Get the Masks\n",
    "            if IS_DEMO:\n",
    "                batch_masks = [\n",
    "                    sum([rle_to_mask(mask, size, size) for mask in batch]) \\\n",
    "                    for batch in pub_ss_df[pub_ss_df.ID.isin(submission_ids[i:(i+BATCH_SIZE)])].mask_rles.values\n",
    "                ]\n",
    "                \n",
    "            \n",
    "        else:\n",
    "            # Step 1: Do Prediction On Batch\n",
    "            cell_segmentations = segmentator.pred_cells([[rgby_image[j] for rgby_image in batch_rgby_images] for j in [0, 3, 2]])\n",
    "            nuc_segmentations = segmentator.pred_nuclei([rgby_image[2] for rgby_image in batch_rgby_images])\n",
    "\n",
    "            # Step 2: Perform Cell Labelling on Batch\n",
    "            batch_masks = [label_cell(nuc_seg, cell_seg)[1].astype(np.uint8) for nuc_seg, cell_seg in zip(nuc_segmentations, cell_segmentations)]\n",
    "\n",
    "            # Step 3: Reshape the RGBY Images so They Are Channels Last Across the Batch\n",
    "            batch_rgb_images = [rgby_image.transpose(1,2,0)[..., :-1] for rgby_image in batch_rgby_images]\n",
    "\n",
    "            # Step 4: Get Bounding Boxes For All Cells in All Images in Batch\n",
    "            batch_cell_bboxes = [get_contour_bbox_from_raw(mask) for mask in batch_masks]\n",
    "            \n",
    "            # Step 5: Generate Submission RLEs For the Batch\n",
    "            submission_rles = [[binary_mask_to_ascii(mask, mask_val=cell_id) for cell_id in range(1, mask.max()+1)] for mask in batch_masks]\n",
    "    \n",
    "        # Step 6: Cut Out, Pad to Square, and Resize to 224x224\n",
    "        batch_cell_tiles = [[\n",
    "            cv2.resize(\n",
    "                pad_to_square(\n",
    "                    rgb_image[bbox[1]:bbox[3], bbox[0]:bbox[2], ...]), \n",
    "                TILE_SIZE, interpolation=cv2.INTER_CUBIC) for bbox in bboxes] \n",
    "            for bboxes, rgb_image in zip(batch_cell_bboxes, batch_rgb_images)\n",
    "        ]\n",
    "\n",
    "        # Step 7: (OPTIONAL) Test Time Augmentation\n",
    "        if DO_TTA:\n",
    "            tta_batch_cell_tiles = [tta(tf.cast(ct, dtype=tf.float32), repeats=TTA_REPEATS) for ct in batch_cell_tiles]\n",
    "        else:\n",
    "            batch_cell_tiles = [tf.cast(ct, dtype=tf.float32) for ct in batch_cell_tiles]\n",
    "        \n",
    "        # Step 8: Perform Inference \n",
    "        if DO_TTA:\n",
    "            tta_batch_o_preds = [[inference_model.predict(ct) for ct in bct] for bct in tta_batch_cell_tiles]\n",
    "            batch_o_preds = [tf.keras.layers.Average()(tta_o_preds).numpy() for tta_o_preds in tta_batch_o_preds]\n",
    "        else:\n",
    "            batch_o_preds = [inference_model.predict(cell_tiles) for cell_tiles in batch_cell_tiles]\n",
    "            \n",
    "        # Step 9: Post-Process\n",
    "        batch_confs = [[pred[np.where(pred>CONF_THRESH)] for pred in o_preds] for o_preds in batch_o_preds]\n",
    "        batch_preds = [[np.where(pred>CONF_THRESH)[0] for pred in o_preds] for o_preds in batch_o_preds]\n",
    "\n",
    "        for j, preds in enumerate(batch_preds):\n",
    "            for k in range(len(preds)):\n",
    "                if preds[k].size==0:\n",
    "                    batch_preds[j][k]=np.array([18,])\n",
    "                    batch_confs[j][k]=np.array([1-np.max(batch_o_preds[j][k]),])\n",
    "        \n",
    "        # Optional Viz Step\n",
    "        if IS_DEMO:\n",
    "           # print(\"\\n... DEMO IMAGES ...\\n\")\n",
    "            for rgb_images, masks, preds, confs in zip(batch_rgb_images, batch_masks, batch_preds, batch_confs):\n",
    "                plot_predictions(rgb_images, masks, preds, confs=confs, fill_alpha=0.2, lbl_as_str=True)\n",
    "\n",
    "        \n",
    "        # Step 10: Format Predictions To Create Prediction String Easily\n",
    "        submission_rles = [flatten_list_of_lists([[m,]*len(p) for m, p in zip(masks, preds)]) for masks, preds in zip(submission_rles, batch_preds)]\n",
    "        batch_preds = [flatten_list_of_lists(preds, to_string=True) for preds in batch_preds]\n",
    "        batch_confs = [[f\"{conf:.4f}\" for cell_confs in confs for conf in cell_confs] for confs in batch_confs]\n",
    "        \n",
    "        # Step 11: Save Predictions to Be Added to Dataframe At The End\n",
    "        predictions.extend([\" \".join(flatten_list_of_lists(zip(*[preds,confs,masks]))) for preds, confs, masks in zip(batch_preds, batch_confs, submission_rles)])\n",
    "sub_df[\"PredictionString\"] = predictions\n",
    "\n",
    "print(\"\\n... TEST DATAFRAME ...\\n\")\n",
    "display(sub_df.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.031684,
     "end_time": "2021-05-06T21:24:39.644922",
     "exception": false,
     "start_time": "2021-05-06T21:24:39.613238",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a style=\"text-align: font-family: Verdana; font-size: 24px; font-style: normal; font-weight: bold; text-decoration: none; text-transform: none; letter-spacing: 3px; color: navy; background-color: #ffffff;\" id=\"submit\">5&nbsp;&nbsp;SUBMIT</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-06T21:24:39.710657Z",
     "iopub.status.busy": "2021-05-06T21:24:39.709936Z",
     "iopub.status.idle": "2021-05-06T21:24:39.801365Z",
     "shell.execute_reply": "2021-05-06T21:24:39.801978Z"
    },
    "papermill": {
     "duration": 0.122956,
     "end_time": "2021-05-06T21:24:39.802170",
     "exception": false,
     "start_time": "2021-05-06T21:24:39.679214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>ImageWidth</th>\n",
       "      <th>ImageHeight</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0040581b-f1f2-4fbe-b043-b6bfea5404bb</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>0 0.0107 eNqtVL0OgyAQfiVIz4TBoYODiVdKE2odGDqYR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>004a270d-34a2-4d60-bbe4-365fca868193</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>0 0.0003 eNoLCAhINDDJyTc0AIMYwxQ/CCvBwAHCsPCA0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00537262-883c-4b37-a3a1-a4931b6faea5</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>0 0.0001 eNozyDEKyTU0AAMTHwOsACaOi7ZxQaUTDBwgj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00c9a1c9-2f06-476f-8b0d-6d01032874a2</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>0 0.0010 eNrFk7ESwiAMhl8puWNgYOjAwIAsou3AwNC7g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0173029a-161d-40ef-af28-2342915b22fb</td>\n",
       "      <td>3072</td>\n",
       "      <td>3072</td>\n",
       "      <td>0 0.0002 eNq9VMEKwjAM/aVQsE7ZRSgbCKVzh1mnVK1zj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>01a14326-67b8-43b0-ac7a-ba6dfb3c38ad</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>0 0.0015 eNrVU8EKwyAM/aU4ehAmrAwHPUjrwUMPMtPhY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>020a29cf-2c24-478b-8603-c22a90dc3e31</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>0 0.0010 eNq1lltvqzAMgP8SDtmZtKcjHWlSN+KulG3QJ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>02425037-3048-4ff3-9c0a-e9fc2d033e32</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>0 0.0002 eNp9lE1vwjAMhv9SItKPAwcOSIS1ynLIpIBcM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>02531b54-078d-4a33-9c9c-0632b58c0a9a</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>0 0.3507 eNozSLBISDc0IAr4mGDn4xKnFZ9U91DL/dRWT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>025f04f1-6c68-4606-b34b-047738dd4804</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>0 0.0012 eNpLCU5INbJJyTc0AIEY/xQDCMjxC4EIGXhY4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>02861579-97fb-4482-a613-356e0bf5d090</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>0 0.4442 eNrF2M1y2zgMAOBXEvzXHHLIwTsTuTKCxGjCd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>02b3c5aa-d70c-49d1-b3e5-3f5cc10375ca</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>0 0.0008 eNozSDWKTjY0wAKMfTHFTHwQMjB5iJiVG4SXY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>02f9ee97-bf2e-4d9d-bdfd-b903ec2e79c0</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>0 0.0001 eNrFlc2SgjAMgF/JDBbF2eviwmimKvWvIAh10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>036cd088-40fc-4ab0-a131-a6c02f02440a</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>0 0.3556 eNqFUMFOwzAM/SWb5VCJSBvQQydtTgQ+RCxs7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>03aa8433-b927-4495-a6e2-d03cdc17d76b</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>0 0.3130 eNql1m1T2zAMAOC/ZJXCwtHdeluhLySKNgQY0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      ID  ImageWidth  ImageHeight  \\\n",
       "0   0040581b-f1f2-4fbe-b043-b6bfea5404bb        2048         2048   \n",
       "1   004a270d-34a2-4d60-bbe4-365fca868193        2048         2048   \n",
       "2   00537262-883c-4b37-a3a1-a4931b6faea5        2048         2048   \n",
       "3   00c9a1c9-2f06-476f-8b0d-6d01032874a2        2048         2048   \n",
       "4   0173029a-161d-40ef-af28-2342915b22fb        3072         3072   \n",
       "5   01a14326-67b8-43b0-ac7a-ba6dfb3c38ad        2048         2048   \n",
       "6   020a29cf-2c24-478b-8603-c22a90dc3e31        1728         1728   \n",
       "7   02425037-3048-4ff3-9c0a-e9fc2d033e32        2048         2048   \n",
       "8   02531b54-078d-4a33-9c9c-0632b58c0a9a        2048         2048   \n",
       "9   025f04f1-6c68-4606-b34b-047738dd4804        2048         2048   \n",
       "10  02861579-97fb-4482-a613-356e0bf5d090        2048         2048   \n",
       "11  02b3c5aa-d70c-49d1-b3e5-3f5cc10375ca        1728         1728   \n",
       "12  02f9ee97-bf2e-4d9d-bdfd-b903ec2e79c0        1728         1728   \n",
       "13  036cd088-40fc-4ab0-a131-a6c02f02440a        2048         2048   \n",
       "14  03aa8433-b927-4495-a6e2-d03cdc17d76b        2048         2048   \n",
       "\n",
       "                                     PredictionString  \n",
       "0   0 0.0107 eNqtVL0OgyAQfiVIz4TBoYODiVdKE2odGDqYR...  \n",
       "1   0 0.0003 eNoLCAhINDDJyTc0AIMYwxQ/CCvBwAHCsPCA0...  \n",
       "2   0 0.0001 eNozyDEKyTU0AAMTHwOsACaOi7ZxQaUTDBwgj...  \n",
       "3   0 0.0010 eNrFk7ESwiAMhl8puWNgYOjAwIAsou3AwNC7g...  \n",
       "4   0 0.0002 eNq9VMEKwjAM/aVQsE7ZRSgbCKVzh1mnVK1zj...  \n",
       "5   0 0.0015 eNrVU8EKwyAM/aU4ehAmrAwHPUjrwUMPMtPhY...  \n",
       "6   0 0.0010 eNq1lltvqzAMgP8SDtmZtKcjHWlSN+KulG3QJ...  \n",
       "7   0 0.0002 eNp9lE1vwjAMhv9SItKPAwcOSIS1ynLIpIBcM...  \n",
       "8   0 0.3507 eNozSLBISDc0IAr4mGDn4xKnFZ9U91DL/dRWT...  \n",
       "9   0 0.0012 eNpLCU5INbJJyTc0AIEY/xQDCMjxC4EIGXhY4...  \n",
       "10  0 0.4442 eNrF2M1y2zgMAOBXEvzXHHLIwTsTuTKCxGjCd...  \n",
       "11  0 0.0008 eNozSDWKTjY0wAKMfTHFTHwQMjB5iJiVG4SXY...  \n",
       "12  0 0.0001 eNrFlc2SgjAMgF/JDBbF2eviwmimKvWvIAh10...  \n",
       "13  0 0.3556 eNqFUMFOwzAM/SWb5VCJSBvQQydtTgQ+RCxs7...  \n",
       "14  0 0.3130 eNql1m1T2zAMAOC/ZJXCwtHdeluhLySKNgQY0...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ss_df = ss_df.merge(sub_df, how=\"left\", on=\"ID\")\n",
    "ss_df[\"PredictionString\"] = ss_df.apply(create_pred_col, axis=1)\n",
    "ss_df = ss_df.drop(columns=[\"PredictionString_x\", \"PredictionString_y\"])\n",
    "#ss_df.to_csv(\"/kaggle/working/submission.csv\", index=False)\n",
    "display(ss_df.head(15))\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-06T21:24:39.867370Z",
     "iopub.status.busy": "2021-05-06T21:24:39.866292Z",
     "iopub.status.idle": "2021-05-06T21:24:40.789735Z",
     "shell.execute_reply": "2021-05-06T21:24:40.789094Z"
    },
    "papermill": {
     "duration": 0.959439,
     "end_time": "2021-05-06T21:24:40.789904",
     "exception": false,
     "start_time": "2021-05-06T21:24:39.830465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/new-work/model_green.h5\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../input/new-work/model_green.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-06T21:24:40.858995Z",
     "iopub.status.busy": "2021-05-06T21:24:40.858250Z",
     "iopub.status.idle": "2021-05-06T21:24:40.873858Z",
     "shell.execute_reply": "2021-05-06T21:24:40.874445Z"
    },
    "papermill": {
     "duration": 0.054181,
     "end_time": "2021-05-06T21:24:40.874700",
     "exception": false,
     "start_time": "2021-05-06T21:24:40.820519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def auto_select_accelerator():\n",
    "    try:\n",
    "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "        tf.config.experimental_connect_to_cluster(tpu)\n",
    "        tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "        print(\"Running on TPU:\", tpu.master())\n",
    "    except ValueError:\n",
    "        strategy = tf.distribute.get_strategy()\n",
    "    print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n",
    "\n",
    "    return strategy\n",
    "\n",
    "\n",
    "def build_decoder(with_labels=True, target_size=(300, 300), ext='jpg'):\n",
    "    \n",
    "    def decode(path):\n",
    "        file_bytes = tf.io.read_file(path)\n",
    "        if ext == 'png':\n",
    "            img = tf.image.decode_png(file_bytes, channels=3)\n",
    "        elif ext in ['jpg', 'jpeg']:\n",
    "            img = tf.image.decode_jpeg(file_bytes, channels=3)\n",
    "        else:\n",
    "            raise ValueError(\"Image extension not supported\")\n",
    "        img = tf.cast(img, tf.float32) / 255.0\n",
    "        img = tf.image.resize(img, target_size)\n",
    "        return img\n",
    "    \n",
    "    def decode_with_labels(path, label):\n",
    "        return decode(path), label\n",
    "\n",
    "    return decode_with_labels if with_labels else decode\n",
    "\n",
    "\n",
    "def build_augmenter(with_labels=True):\n",
    "    \n",
    "    def augment(img):\n",
    "        img = tf.image.random_flip_left_right(img)\n",
    "        img = tf.image.random_flip_up_down(img)\n",
    "        return img\n",
    "    \n",
    "    def augment_with_labels(img, label):\n",
    "        return augment(img), label\n",
    "    \n",
    "    return augment_with_labels if with_labels else augment\n",
    "\n",
    "\n",
    "def build_dataset(paths, labels=None, bsize=32, cache=True,\n",
    "                  decode_fn=None, augment_fn=None,\n",
    "                  augment=True, repeat=True, shuffle=1024, \n",
    "                  cache_dir=\"\"):\n",
    "    if cache_dir != \"\" and cache is True:\n",
    "        os.makedirs(cache_dir, exist_ok=True)\n",
    "    if decode_fn is None:\n",
    "        decode_fn = build_decoder(labels is not None)\n",
    "    if augment_fn is None:\n",
    "        augment_fn = build_augmenter(labels is not None)\n",
    "\n",
    "    AUTO = tf.data.experimental.AUTOTUNE\n",
    "    slices = paths if labels is None else (paths, labels)\n",
    "\n",
    "    dset = tf.data.Dataset.from_tensor_slices(slices)\n",
    "    dset = dset.map(decode_fn, num_parallel_calls=AUTO)\n",
    "    dset = dset.cache(cache_dir) if cache else dset\n",
    "    dset = dset.map(augment_fn, num_parallel_calls=AUTO) if augment else dset\n",
    "    dset = dset.repeat() if repeat else dset\n",
    "    dset = dset.shuffle(shuffle) if shuffle else dset\n",
    "    dset = dset.batch(bsize).prefetch(AUTO)\n",
    "\n",
    "    return dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-06T21:24:40.936164Z",
     "iopub.status.busy": "2021-05-06T21:24:40.935297Z",
     "iopub.status.idle": "2021-05-06T21:32:12.368616Z",
     "shell.execute_reply": "2021-05-06T21:32:12.368025Z"
    },
    "papermill": {
     "duration": 451.465324,
     "end_time": "2021-05-06T21:32:12.368789",
     "exception": false,
     "start_time": "2021-05-06T21:24:40.903465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on 1 replicas\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Functional)        (None, 19, 19, 2048)      23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 19)                38931     \n",
      "=================================================================\n",
      "Total params: 23,626,643\n",
      "Trainable params: 23,573,523\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n",
      "35/35 [==============================] - 433s 12s/step\n",
      "HPA_MODELS = False\n"
     ]
    }
   ],
   "source": [
    "HPA_MODELS = False\n",
    "COMPETITION_NAME = \"hpa-single-cell-image-classification\"\n",
    "strategy = auto_select_accelerator()\n",
    "BATCH_SIZE = strategy.num_replicas_in_sync * 16\n",
    "\n",
    "IMSIZE = (224, 240, 260, 300, 380, 456, 528, 600, 720)\n",
    "\n",
    "load_dir = f\"/kaggle/input/{COMPETITION_NAME}/\"\n",
    "sub_df = pd.read_csv('../input/hpa-single-cell-image-classification/sample_submission.csv')\n",
    "sub_df = sub_df.drop(sub_df.columns[1:],axis=1)\n",
    "for i in range(19):\n",
    "    sub_df[f'{i}'] = pd.Series(np.zeros(sub_df.shape[0]))\n",
    "\n",
    "if HPA_MODELS:\n",
    "    colours = ['blue', 'green', 'red', 'yellow']\n",
    "    sub_dfs = []\n",
    "    for colour in colours:\n",
    "        test_paths = load_dir + \"/test/\" + sub_df['ID'] + '_' + colour + '.png' # Start making individul label\n",
    "        label_cols = sub_df.columns[1:] # Get the multi-labels\n",
    "\n",
    "        test_decoder = build_decoder(with_labels=False, target_size=(IMSIZE[-2], IMSIZE[-2]))\n",
    "        dtest = build_dataset(\n",
    "            test_paths, bsize=BATCH_SIZE, repeat=False, \n",
    "            shuffle=False, augment=False, cache=False,\n",
    "            decode_fn=test_decoder\n",
    "        )\n",
    "\n",
    "        with strategy.scope():\n",
    "            model = tf.keras.models.load_model(\n",
    "                f'../input/hpa-models/effb7_individual_model_{colour}.h5'\n",
    "            )\n",
    "\n",
    "        model.summary()\n",
    "        sub_df[label_cols] = model.predict(dtest, verbose=1)\n",
    "        sub_dfs.append(sub_df)\n",
    "\n",
    "        # if colour == 'green':\n",
    "        # sub_df = pd.concat((sub_df.ID, (sub_dfs[0].iloc[:, 1:] + sub_dfs[1].iloc[:, 1:])/2), axis=1)\n",
    "        # break\n",
    "\n",
    "        if colour == 'yellow':\n",
    "            sub_df = pd.concat((sub_df.ID, (\n",
    "            sub_dfs[0].iloc[:, 1:] + sub_dfs[1].iloc[:, 1:] + sub_dfs[2].iloc[:, 1:] + sub_dfs[3].iloc[:, 1:]\n",
    "            )/4), axis=1)\n",
    "else:\n",
    "    test_paths = load_dir + \"/test/\" + sub_df['ID'] + '_' + 'green' + '.png' # Start making individul label\n",
    "    label_cols = sub_df.columns[1:] # Get the multi-labels\n",
    "\n",
    "    test_decoder = build_decoder(with_labels=False, target_size=(IMSIZE[-2], IMSIZE[-2]))\n",
    "    dtest = build_dataset(\n",
    "        test_paths, bsize=BATCH_SIZE, repeat=False, \n",
    "        shuffle=False, augment=False, cache=False,\n",
    "        decode_fn=test_decoder\n",
    "    )\n",
    "\n",
    "    with strategy.scope():\n",
    "        model = tf.keras.models.load_model('../input/new-work/model_green.h5')\n",
    "\n",
    "    model.summary()\n",
    "    sub_df[label_cols] = model.predict(dtest, verbose=1)\n",
    "\n",
    "ss_df = pd.merge(ss_df, sub_df, on = 'ID', how = 'left')\n",
    "\n",
    "for row in range(ss_df.shape[0]):\n",
    "    pred = ss_df.loc[row,'PredictionString']\n",
    "    pred_split = pred.split()\n",
    "    for j in range(int(len(pred_split)/3)):        \n",
    "        for k in range(19):\n",
    "            if int(pred_split[ 3*j ]) == k:\n",
    "                p = pred_split[ 3*j + 1 ]               \n",
    "                pred_split[ 3*j + 1 ] = str( ss_df.loc[row, f'{k}']*0.6 + float(p)*0.4 )\n",
    "    ss_df.loc[row,'PredictionString'] = ' '.join(pred_split)\n",
    "\n",
    "ss_df = ss_df[['ID','ImageWidth','ImageHeight','PredictionString']]\n",
    "ss_df.to_csv('submission.csv',index = False)\n",
    "\n",
    "print(f'HPA_MODELS = {HPA_MODELS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.040124,
     "end_time": "2021-05-06T21:32:12.450422",
     "exception": false,
     "start_time": "2021-05-06T21:32:12.410298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "\n",
    "    \n",
    "       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.039844,
     "end_time": "2021-05-06T21:32:12.531934",
     "exception": false,
     "start_time": "2021-05-06T21:32:12.492090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.039786,
     "end_time": "2021-05-06T21:32:12.612238",
     "exception": false,
     "start_time": "2021-05-06T21:32:12.572452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-06T21:32:12.717799Z",
     "iopub.status.busy": "2021-05-06T21:32:12.700190Z",
     "iopub.status.idle": "2021-05-06T21:32:12.724896Z",
     "shell.execute_reply": "2021-05-06T21:32:12.724139Z"
    },
    "papermill": {
     "duration": 0.072796,
     "end_time": "2021-05-06T21:32:12.725057",
     "exception": false,
     "start_time": "2021-05-06T21:32:12.652261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>ImageWidth</th>\n",
       "      <th>ImageHeight</th>\n",
       "      <th>PredictionString</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0040581b-f1f2-4fbe-b043-b6bfea5404bb</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>0 0.3216391136932373 eNqtVL0OgyAQfiVIz4TBoYODi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>004a270d-34a2-4d60-bbe4-365fca868193</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>0 0.006581852788925171 eNoLCAhINDDJyTc0AIMYwxQ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00537262-883c-4b37-a3a1-a4931b6faea5</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>0 0.002802371301651001 eNozyDEKyTU0AAMTHwOsACa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00c9a1c9-2f06-476f-8b0d-6d01032874a2</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>0 0.0005206636428833008 eNrFk7ESwiAMhl8puWNgYO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0173029a-161d-40ef-af28-2342915b22fb</td>\n",
       "      <td>3072</td>\n",
       "      <td>3072</td>\n",
       "      <td>0 0.030327968435287473 eNq9VMEKwjAM/aVQsE7ZRSg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>fea47298-266a-4cf4-93bd-55d1bcc2fc7d</td>\n",
       "      <td>1728</td>\n",
       "      <td>1728</td>\n",
       "      <td>0 0.07252844084739685 eNqFUMEOgjAM/aU3tzijN02I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>feb955db-6c07-4717-a98b-92236c8e01d8</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>0 0.0009903775024414062 eNrFlU2L2zAQQP+SJdvBh2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>fefb9bb7-934a-40d1-8d2f-210265857388</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>0 0.13548268436431884 eNoziLFKSTU0QAEmPgZkAR8T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>ff069fa2-d948-408e-91b3-034cfea428d1</td>\n",
       "      <td>3072</td>\n",
       "      <td>3072</td>\n",
       "      <td>0 0.08557492047309875 eNoLCk2KMMoxDMkzMoCBNL8g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>ff23eea9-4bbe-42af-a8da-9ae16321fc6d</td>\n",
       "      <td>2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>0 0.009925978698730468 eNq9ksFqwzAMhl8pauPNHTk...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>559 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       ID  ImageWidth  ImageHeight  \\\n",
       "0    0040581b-f1f2-4fbe-b043-b6bfea5404bb        2048         2048   \n",
       "1    004a270d-34a2-4d60-bbe4-365fca868193        2048         2048   \n",
       "2    00537262-883c-4b37-a3a1-a4931b6faea5        2048         2048   \n",
       "3    00c9a1c9-2f06-476f-8b0d-6d01032874a2        2048         2048   \n",
       "4    0173029a-161d-40ef-af28-2342915b22fb        3072         3072   \n",
       "..                                    ...         ...          ...   \n",
       "554  fea47298-266a-4cf4-93bd-55d1bcc2fc7d        1728         1728   \n",
       "555  feb955db-6c07-4717-a98b-92236c8e01d8        2048         2048   \n",
       "556  fefb9bb7-934a-40d1-8d2f-210265857388        2048         2048   \n",
       "557  ff069fa2-d948-408e-91b3-034cfea428d1        3072         3072   \n",
       "558  ff23eea9-4bbe-42af-a8da-9ae16321fc6d        2048         2048   \n",
       "\n",
       "                                      PredictionString  \n",
       "0    0 0.3216391136932373 eNqtVL0OgyAQfiVIz4TBoYODi...  \n",
       "1    0 0.006581852788925171 eNoLCAhINDDJyTc0AIMYwxQ...  \n",
       "2    0 0.002802371301651001 eNozyDEKyTU0AAMTHwOsACa...  \n",
       "3    0 0.0005206636428833008 eNrFk7ESwiAMhl8puWNgYO...  \n",
       "4    0 0.030327968435287473 eNq9VMEKwjAM/aVQsE7ZRSg...  \n",
       "..                                                 ...  \n",
       "554  0 0.07252844084739685 eNqFUMEOgjAM/aU3tzijN02I...  \n",
       "555  0 0.0009903775024414062 eNrFlU2L2zAQQP+SJdvBh2...  \n",
       "556  0 0.13548268436431884 eNoziLFKSTU0QAEmPgZkAR8T...  \n",
       "557  0 0.08557492047309875 eNoLCk2KMMoxDMkzMoCBNL8g...  \n",
       "558  0 0.009925978698730468 eNq9ksFqwzAMhl8pauPNHTk...  \n",
       "\n",
       "[559 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10945.319724,
   "end_time": "2021-05-06T21:32:16.195270",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-06T18:29:50.875546",
   "version": "2.2.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "09a5b1760edb40809a583174c55fb975": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0ee6f97fb8c449f6a6d354a78a78537e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "1a79478ca1454575a01e4d2499e234b7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_322c6e4d5fe64483a8a6281779b0f61f",
       "placeholder": "​",
       "style": "IPY_MODEL_aa9652df4e5a42eeb4834a4db43a6d22",
       "value": " 9/9 [13:53&lt;00:00, 83.31s/it]"
      }
     },
     "29569159847c444f93341c158c93849d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c3c490ad8195485ab26755d183fae4e5",
       "placeholder": "​",
       "style": "IPY_MODEL_c605e6f074bc4d49845769e13e086043",
       "value": "100%"
      }
     },
     "322c6e4d5fe64483a8a6281779b0f61f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "32fbb596525f45b4a70249e4cb5dd265": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c475b2fd7f9b405fa6d3f9741b9b0ffb",
       "placeholder": "​",
       "style": "IPY_MODEL_639777ea952a40c78d40e74c6c558acc",
       "value": " 58/58 [2:20:28&lt;00:00, 148.52s/it]"
      }
     },
     "377f7119c30848338128a948481b2edf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3794128f5d1b48b6aed4398c201d55bd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4101600674e94fceaf65fbda34c12f3d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6c1b55ce6b19471ebbe5bbb1f84f4947",
       "max": 9.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_89505234afdb4406b74817f6926b923d",
       "value": 9.0
      }
     },
     "47115f8456bc4656b80783ad555fecba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f5d64221ad964a0bb358d4d9a80bf859",
       "max": 58.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b7b6967543e24c6185e51cd895d1ee25",
       "value": 58.0
      }
     },
     "5678e66867fd496fac229a146bb5aa47": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5a1cdd122caf4596832b07c4d53e4349": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ea1bdda73d9e4fcd812e2ceff29be52e",
       "placeholder": "​",
       "style": "IPY_MODEL_6baea5d199114825bb2d20edd64b7ec4",
       "value": "100%"
      }
     },
     "5b6ea5b2aa364b66aff589e7a5cb2cc0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9d288a6f1fa7479ab6a274e5cac3468b",
       "placeholder": "​",
       "style": "IPY_MODEL_0ee6f97fb8c449f6a6d354a78a78537e",
       "value": " 4/4 [17:26&lt;00:00, 246.09s/it]"
      }
     },
     "5c588e86df104b53ad893aa882f446ef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_09a5b1760edb40809a583174c55fb975",
       "max": 4.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ce9919398ba4450b97e281c7d9d63bdf",
       "value": 4.0
      }
     },
     "639777ea952a40c78d40e74c6c558acc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "6baea5d199114825bb2d20edd64b7ec4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "6c1b55ce6b19471ebbe5bbb1f84f4947": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7cede8fb3e7b42298e962a61b684d345": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_dd52222fdfb54efa8312327c22b96d54",
       "placeholder": "​",
       "style": "IPY_MODEL_9ceb36dfbbbf421881d8013158beb280",
       "value": "100%"
      }
     },
     "7f1ed1ed69cd4812b6cd2c8e607c030e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7cede8fb3e7b42298e962a61b684d345",
        "IPY_MODEL_5c588e86df104b53ad893aa882f446ef",
        "IPY_MODEL_5b6ea5b2aa364b66aff589e7a5cb2cc0"
       ],
       "layout": "IPY_MODEL_377f7119c30848338128a948481b2edf"
      }
     },
     "7f886556b8924afc9b588efce6a8d515": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5a1cdd122caf4596832b07c4d53e4349",
        "IPY_MODEL_47115f8456bc4656b80783ad555fecba",
        "IPY_MODEL_32fbb596525f45b4a70249e4cb5dd265"
       ],
       "layout": "IPY_MODEL_5678e66867fd496fac229a146bb5aa47"
      }
     },
     "89505234afdb4406b74817f6926b923d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "9ceb36dfbbbf421881d8013158beb280": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "9d288a6f1fa7479ab6a274e5cac3468b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "aa9652df4e5a42eeb4834a4db43a6d22": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b430a6b1ae0749cfbe48602db0d93709": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_29569159847c444f93341c158c93849d",
        "IPY_MODEL_4101600674e94fceaf65fbda34c12f3d",
        "IPY_MODEL_1a79478ca1454575a01e4d2499e234b7"
       ],
       "layout": "IPY_MODEL_3794128f5d1b48b6aed4398c201d55bd"
      }
     },
     "b7b6967543e24c6185e51cd895d1ee25": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c3c490ad8195485ab26755d183fae4e5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c475b2fd7f9b405fa6d3f9741b9b0ffb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c605e6f074bc4d49845769e13e086043": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ce9919398ba4450b97e281c7d9d63bdf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "dd52222fdfb54efa8312327c22b96d54": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ea1bdda73d9e4fcd812e2ceff29be52e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f5d64221ad964a0bb358d4d9a80bf859": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
